import pandas as pd
import numpy as np
import pickle
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
from natasha import Segmenter, Doc
import csv
from telegram import Update, ReplyKeyboardMarkup, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes, CallbackQueryHandler
import os
from datetime import datetime
from Levenshtein import ratio


'''
–ü–µ—Ä–µ–º–Ω–Ω—ã–µ –∏ –º–µ—Ç–æ–¥—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —á–∞—Ç-–±–æ—Ç–∞
'''
token = os.getenv("API_KEY")

# –•—Ä–∞–Ω–∏–ª–∏—â–µ —Å–æ—Å—Ç–æ—è–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
USER_DATA = {}

# –ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
feedback_keyboard = ReplyKeyboardMarkup(
    [["1", "2", "3", "4", "5"]], one_time_keyboard=True, resize_keyboard=True
)


# –ö–æ–º–∞–Ω–¥–∞ /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    student_id = update.message.chat_id

    # –°–±—Ä–æ—Å –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –Ω–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
    if student_id in USER_DATA:
        del USER_DATA[student_id]
    else:
        await update.message.reply_text(
            "–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å!"
        )

    await update.message.reply_text(
        "–ù–∞–ø–∏—à–∏—Ç–µ –æ —Å–≤–æ–∏—Ö –∏–Ω—Ç–µ—Ä–µ—Å–∞—Ö, —á—Ç–æ–±—ã –º—ã –º–æ–≥–ª–∏ –ø–æ–¥–æ–±—Ä–∞—Ç—å –¥–ª—è –≤–∞—Å –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —ç–ª–µ–∫—Ç–∏–≤—ã."
    )


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã
def get_keyboard(current_page, total_pages):
    # –°–æ–∑–¥–∞–µ–º –∫–Ω–æ–ø–∫–∏ "–ù–∞–∑–∞–¥" –∏ "–í–ø–µ—Ä–µ–¥"
    navigation_buttons = [
        InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="previous_page"),
        InlineKeyboardButton("‚û°Ô∏è –í–ø–µ—Ä–µ–¥", callback_data="next_page"),
    ]

    # –ö–Ω–æ–ø–∫–∞ "–û—Ü–µ–Ω–∏—Ç—å –±–æ—Ç" –≤—Ç–æ—Ä–∞—è —Å—Ç—Ä–æ–∫–∞
    feedback_button = [
        InlineKeyboardButton("üìù –û—Ü–µ–Ω–∏—Ç—å –±–æ—Ç", callback_data="feedback")
    ]

    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É (–ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –¥–ª—è –Ω–∞–≤–∏–≥–∞—Ü–∏–∏, –≤—Ç–æ—Ä–∞—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏)
    keyboard = [
        navigation_buttons,  # –ö–Ω–æ–ø–∫–∏ "–ù–∞–∑–∞–¥" –∏ "–í–ø–µ—Ä–µ–¥"
        feedback_button,  # –ö–Ω–æ–ø–∫–∞ "–û—Ü–µ–Ω–∏—Ç—å –±–æ—Ç"
    ]

    return InlineKeyboardMarkup(keyboard)


# –ü—Ä–∏–º–µ—Ä —Ñ—É–Ω–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä–∞—è –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∏–ª–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–Ω–æ–ø–æ–∫
async def handle_button(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()  # –û—Ç–≤–µ—Ç –Ω–∞ callback –∑–∞–ø—Ä–æ—Å (–≤–∞–∂–Ω–æ –¥–ª—è Telegram API)

    student_id = query.message.chat.id

    if query.data == "feedback":
        # –ö–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–∂–∏–º–∞–µ—Ç –Ω–∞ "–û—Ü–µ–Ω–∏—Ç—å –±–æ—Ç"
        await query.message.reply_text(
            "–ö–∞–∫ –≤—ã –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç–µ –ø–æ–¥–±–æ—Ä —ç–ª–µ–∫—Ç–∏–≤–æ–≤? (–û—Ü–µ–Ω–∏—Ç–µ –æ—Ç 1 –¥–æ 5)",
            reply_markup=feedback_keyboard
        )
        USER_DATA[student_id]["awaiting_satisfaction"] = True  # –§–ª–∞–≥ –¥–ª—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ü–µ–Ω–∫–∏
        return

    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤–ø–µ—Ä–µ–¥ –∏ –Ω–∞–∑–∞–¥
    current_page = USER_DATA[student_id]["current_page"]
    pages = USER_DATA[student_id]["pages"]

    if query.data == "next_page":
        if current_page < len(pages) - 1:
            USER_DATA[student_id]["current_page"] += 1
            current_page = USER_DATA[student_id]["current_page"]
    elif query.data == "previous_page":
        if current_page > 0:
            USER_DATA[student_id]["current_page"] -= 1
            current_page = USER_DATA[student_id]["current_page"]

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    response_text = create_response(pages, current_page)

    # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –∏ –∫–Ω–æ–ø–∫–∞–º–∏
    await query.edit_message_text(
        text=response_text,
        reply_markup=get_keyboard(current_page, len(pages))  # –û–±–Ω–æ–≤–ª—è–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É
    )


def create_response(pages, current_page):
    response_text = (
            "–†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ —ç–ª–µ–∫—Ç–∏–≤—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–∞—à–∏—Ö –∏–Ω—Ç–µ—Ä–µ—Å–æ–≤:\n" +
            "\n".join(
                [
                    f"{5 * current_page + idx}. {el[0]} \nüéì–ú–æ–¥–µ—É—Å: {el[2]}"
                    + (f" \nüìò–û—Ç–∑—ã–≤—É—Å: {el[3]}" if not pd.isna(el[3]) else "")
                    for idx, el in enumerate(pages[current_page], start=1)
                ]
            )
    )
    return response_text


# –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏
def map_electives(input_electives, db_electives, threshold=0.6):
    results = {}
    for input_elective in input_electives:
        best_match = None
        best_score = 0
        for db_elective in db_electives:
            score = ratio(input_elective.lower(), db_elective.lower())
            if score > best_score:
                best_match = db_elective
                best_score = score
        if best_score >= threshold:
            results[input_elective] = best_match
    return list(results.values())


# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    student_id = update.message.chat.id
    user_input = update.message.text

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –¥–∞–Ω–Ω—ã–µ –æ –º–æ–¥–µ–ª—è—Ö
    model_content_data = context.bot_data.get("model_content")
    model_colab_model = context.bot_data.get("svd_model")
    available_el = context.bot_data.get("available_el")

    if not model_content_data or not model_colab_model or not available_el:
        await update.message.reply_text("–û—à–∏–±–∫–∞: –°–µ—Ä–≤–∏—Å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")
        return

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    if student_id not in USER_DATA:
        USER_DATA[student_id] = {}

    # –ï—Å–ª–∏ –±–æ—Ç –æ–∂–∏–¥–∞–µ—Ç –æ—Ü–µ–Ω–∫—É (1-5)
    if USER_DATA[student_id].get("awaiting_rating"):
        if user_input in ["1", "2", "3", "4", "5"]:
            USER_DATA[student_id]["rating"] = int(user_input)
            del USER_DATA[student_id]["awaiting_rating"]  # –ó–∞–≤–µ—Ä—à–∞–µ–º —ç—Ç–∞–ø –æ—Ü–µ–Ω–∫–∏

            # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –æ—Ç–∑—ã–≤
            USER_DATA[student_id]["rating_step"] = "feedback"
            await update.message.reply_text(
                "–°–ø–∞—Å–∏–±–æ –∑–∞ –≤–∞—à—É –æ—Ü–µ–Ω–∫—É! –ù–∞–ø–∏—à–∏—Ç–µ, —á—Ç–æ –≤–∞–º –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å –∏–ª–∏ —á—Ç–æ –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å:",
                reply_markup=None
            )
        else:
            await update.message.reply_text(
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ –æ—Ç 1 –¥–æ 5."
            )
        return

    # –ï—Å–ª–∏ –±–æ—Ç –æ–∂–∏–¥–∞–µ—Ç –æ—Ç–∑—ã–≤
    elif USER_DATA[student_id].get("rating_step") == "feedback":
        USER_DATA[student_id]["feedback"] = user_input
        del USER_DATA[student_id]["rating_step"]

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ CSV
        save_feedback_to_csv(student_id, USER_DATA[student_id])

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏—Ç–æ–≥–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        await update.message.reply_text(
            "–°–ø–∞—Å–∏–±–æ –∑–∞ –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å!\n–ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –Ω–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ, –≤–≤–µ–¥–∏—Ç–µ /start.",
            reply_markup=None
        )
        return

    # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤–≤–µ–ª –∑–∞–ø—Ä–æ—Å –Ω–∞ –ø–æ–¥–±–æ—Ä —ç–ª–µ–∫—Ç–∏–≤–æ–≤
    if "interests" not in USER_DATA[student_id]:
        USER_DATA[student_id]["interests"] = user_input
        await update.message.reply_text(
            '–í–≤–µ–¥–∏—Ç–µ —ç–ª–µ–∫—Ç–∏–≤—ã, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã —É–∂–µ –ø—Ä–æ—à–ª–∏, —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é \n* –µ—Å–ª–∏ —É –≤–∞—Å –µ—â—ë –Ω–µ –±—ã–ª–æ —ç–ª–µ–∫—Ç–∏–≤–æ–≤, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ "."',
            reply_markup=None
        )
        USER_DATA[student_id]["awaiting_completed"] = True
        return

    # –ï—Å–ª–∏ –±–æ—Ç –æ–∂–∏–¥–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–π–¥–µ–Ω–Ω—ã—Ö —ç–ª–µ–∫—Ç–∏–≤–æ–≤
    elif USER_DATA[student_id].get("awaiting_completed"):
        USER_DATA[student_id]["completed_electives"] = user_input
        del USER_DATA[student_id]["awaiting_completed"]

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        completed_electives = USER_DATA[student_id]["completed_electives"]
        interests = USER_DATA[student_id]["interests"]

        recommendations = predict_for_new_student(
            model_content=model_content_data["model"],
            df=model_content_data["df"],
            svd_model=model_colab_model,
            available_el=available_el,
            input_el=completed_electives,
            user_query=interests,
            student_id=str(student_id)
        )

        USER_DATA[student_id]["recommendations"] = recommendations

        # –†–∞–∑–±–∏–≤–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–ø–æ 5 –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ)
        pages = []
        for i in range(0, len(recommendations), 5):
            page = recommendations[i:i + 5]
            pages.append(page)
        USER_DATA[student_id]["pages"] = pages
        USER_DATA[student_id]["current_page"] = 0

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
        current_page = USER_DATA[student_id]["current_page"]
        response_text = create_response(pages, current_page)

        await update.message.reply_text(
            response_text,
            reply_markup=get_keyboard(current_page, len(pages))
        )

        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –æ—Ü–µ–Ω–∫—É
        USER_DATA[student_id]["awaiting_rating"] = True
        await update.message.reply_text(
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–µ –∑–∞–±—É–¥—å—Ç–µ –æ—Ü–µ–Ω–∏—Ç—å —Ä–∞–±–æ—Ç—É –±–æ—Ç–∞.",
            reply_markup=None
        )
        return

    # –ï—Å–ª–∏ –±–æ—Ç –∑–∞–≤–µ—Ä—à–∏–ª –æ—Å–Ω–æ–≤–Ω–æ–π —Å—Ü–µ–Ω–∞—Ä–∏–π –∏ –∂–¥–µ—Ç –Ω–æ–≤—ã—Ö –∫–æ–º–∞–Ω–¥
    await update.message.reply_text(
        "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ /start –¥–ª—è –Ω–∞—á–∞–ª–∞.",
        reply_markup=None
    )


'''
–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –∏ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ —Å–æ–ø—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –º–µ—Ç–æ–¥–æ–≤
'''
# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ Natasha –¥–ª—è –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
segmenter = Segmenter()

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞
def preprocess_text_natasha(text):
    if not isinstance(text, str):
        return ''
    doc = Doc(text)
    doc.segment(segmenter)
    tokens = [token.text.lower() for token in doc.tokens if token.text.isalpha()]
    return ' '.join(tokens)


# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
def load_model_content():
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö, —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ –º–æ–¥–µ–ª–∏
    df = pd.read_csv("bot/courses_data.csv")
    embeddings = np.load("bot/courses_embeddings.npy")
    df['embeddings'] = list(embeddings)
    model = SentenceTransformer("bot/sentence_transformer_model")
    return model, df


# –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ SVD
def load_model_colab():
    with open("bot/svd_model.pkl", "rb") as f:
        svd_model = pickle.load(f)
    return svd_model


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
def predict_for_new_student(model_content, df, svd_model, available_el, input_el, user_query, student_id="new_student"):
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    user_query_processed = preprocess_text_natasha(user_query)
    query_embedding = model_content.encode(user_query_processed)

    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    df['similarity'] = df['embeddings'].apply(lambda x: cosine_similarity([query_embedding], [x])[0][0])

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä–æ–∫—É –≤ —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–π–¥–µ–Ω–Ω—ã—Ö —ç–ª–µ–∫—Ç–∏–≤–æ–≤
    completed_electives_raw = [e.strip() for e in input_el.split(",") if e.strip()]
    completed_electives = map_electives(completed_electives_raw, available_el)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ç–∏–≤–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    recommendations = []
    for elective in df['–ù–∞–∑–≤–∞–Ω–∏–µ –Ω–∞ –û—Ç–∑—ã–≤—É—Å–µ']:
        # –ò—Å–∫–ª—é—á–∞–µ–º —É–∂–µ –ø—Ä–æ–π–¥–µ–Ω–Ω—ã–µ —ç–ª–µ–∫—Ç–∏–≤—ã –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º —Ç–æ–ª—å–∫–æ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —ç–ª–µ–∫—Ç–∏–≤—ã
        # if elective not in completed_electives and elective in actual_el:
        if elective not in completed_electives:
            prediction_svd = svd_model.predict(student_id, elective).est

            # –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –¥–ª—è –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            elective_row = df[df['–ù–∞–∑–≤–∞–Ω–∏–µ –Ω–∞ –û—Ç–∑—ã–≤—É—Å–µ'] == elective]
            elective_embedding = elective_row['embeddings'].values[0]
            similarity_to_query = cosine_similarity([query_embedding], [elective_embedding])[0][0]

            # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ (–∫–æ–Ω—Ç–µ–Ω—Ç–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è + –∫–æ–ª–ª–∞–±–æ—Ä–∞—Ç–∏–≤–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è)
            final_score = 0.2 * prediction_svd + 0.8 * similarity_to_query
            link_m = elective_row['–°—Å—ã–ª–∫–∞ –Ω–∞ –ú–æ–¥–µ—É—Å'].values[0]
            link_o = elective_row['–°—Å—ã–ª–∫–∞ –Ω–∞ –û—Ç–∑—ã–≤—É—Å'].values[0]

            recommendations.append((elective, final_score, link_m, link_o))

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ—Ü–µ–Ω–∫–µ
    recommendations.sort(key=lambda x: x[1], reverse=True)
    return recommendations


'''
–°–æ–∑–¥–∞–Ω–∏–µ CSV-—Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
'''
current_time = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
csv_file = f"feedback/feedback_{current_time}.csv"

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è CSV-—Ñ–∞–π–ª–∞
if not os.path.exists(csv_file):
    with open(csv_file, "w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["student_id", "interests", "recommendations", "satisfaction", "relevance"])

def save_feedback_to_csv(student_id, data):
    fieldnames = ["student_id", "satisfaction", "relevance", "feedback"]
    write_header = not os.path.exists(csv_file)

    with open(csv_file, mode="a", encoding="utf-8", newline="") as file:
        writer = csv.DictWriter(file, fieldnames=fieldnames)

        if write_header:
            writer.writeheader()

        writer.writerow({
            "student_id": student_id,
            "satisfaction": data["rating"],
            "feedback": data.get("feedback", ""),
        })


'''
–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥
'''
def main():
    application = ApplicationBuilder().token(token).build()

    # –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ Excel
    available_el = pd.read_excel("src\courses_combined_data.xlsx")["–ù–∞–∑–≤–∞–Ω–∏–µ –Ω–∞ –û—Ç–∑—ã–≤—É—Å–µ"].dropna().tolist()
    application.bot_data["available_el"] = list(available_el)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...")
    model_content_inst, df = load_model_content()
    application.bot_data["model_content"] = {"model": model_content_inst, "df": df}
    application.bot_data["svd_model"] = load_model_colab()

    print("–ú–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã!")

    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    application.add_handler(CallbackQueryHandler(handle_button))

    print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω. –ù–∞–∂–º–∏—Ç–µ Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏.")
    application.run_polling()



if __name__ == '__main__':
    main()
